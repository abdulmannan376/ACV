{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"SegNet.ipynb","provenance":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"6563a5b2ca844182b758af2f476bdede":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_300b62f3ca3f4067bf448b0e6796c6c6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1660ae5ca4cf483fa1f1a8c4db787766","IPY_MODEL_8e988a3b4c8e46059f1ebafd4d426045"]}},"300b62f3ca3f4067bf448b0e6796c6c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1660ae5ca4cf483fa1f1a8c4db787766":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_aef997ac0ee74cefac0ce087f159ec23","_dom_classes":[],"description":"100%","_model_name":"IntProgressModel","bar_style":"success","max":30,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":30,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_59ac797aa37a4db39703c84338a48526"}},"8e988a3b4c8e46059f1ebafd4d426045":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cc30e90b4242466eb740db5725075643","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 30/30 [00:05&lt;00:00,  5.45it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6787f14e46284260b6fb256848cf4592"}},"aef997ac0ee74cefac0ce087f159ec23":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"59ac797aa37a4db39703c84338a48526":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cc30e90b4242466eb740db5725075643":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6787f14e46284260b6fb256848cf4592":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"sV6npNHILvuX","colab_type":"code","outputId":"27c41eaf-6b68-45ce-e81e-f865f8714f57","executionInfo":{"status":"ok","timestamp":1585050854463,"user_tz":-300,"elapsed":1130,"user":{"displayName":"Abdul Shahid","photoUrl":"","userId":"02009174769082606407"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fwG390LnhaaM","colab_type":"code","colab":{}},"source":["import os\n","import random\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","plt.style.use(\"ggplot\")\n","%matplotlib inline\n","from tqdm import tqdm_notebook, tnrange\n","from itertools import chain\n","from skimage.io import imread, imshow, concatenate_images\n","from skimage.transform import resize\n","from skimage.morphology import label\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from keras.models import Model, load_model\n","from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n","from keras.layers.core import Lambda, RepeatVector, Reshape\n","from keras.layers.convolutional import Conv2D, Conv2DTranspose\n","from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n","from keras.layers.merge import concatenate, add\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","from keras.optimizers import Adam\n","from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","from keras import backend as K"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qWONKCGUhaak","colab_type":"code","colab":{}},"source":["# Set some parameters\n","im_width = 480\n","im_height = 360\n","border = 5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hxziDd2Dhaa_","colab_type":"code","colab":{}},"source":["ids = next(os.walk(\"/content/gdrive/My Drive/avc-dataset/MonuSeg/Training/TissueImages/\"))[2] # list of names all images in the given path\n","X = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)\n","y = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0dykMlywhabP","colab_type":"code","outputId":"2fa1e2aa-35e8-4382-e434-166be61681e3","executionInfo":{"status":"ok","timestamp":1585050860040,"user_tz":-300,"elapsed":6624,"user":{"displayName":"Abdul Shahid","photoUrl":"","userId":"02009174769082606407"}},"colab":{"base_uri":"https://localhost:8080/","height":146,"referenced_widgets":["6563a5b2ca844182b758af2f476bdede","300b62f3ca3f4067bf448b0e6796c6c6","1660ae5ca4cf483fa1f1a8c4db787766","8e988a3b4c8e46059f1ebafd4d426045","aef997ac0ee74cefac0ce087f159ec23","59ac797aa37a4db39703c84338a48526","cc30e90b4242466eb740db5725075643","6787f14e46284260b6fb256848cf4592"]}},"source":["# tqdm is used to display the progress bar\n","for n, id_ in tqdm_notebook(enumerate(ids), total=len(ids)):\n","    # Load images\n","    img = load_img(\"/content/gdrive/My Drive/avc-dataset/MonuSeg/Training/TissueImages/\"+id_, grayscale=True)\n","    x_img = img_to_array(img)\n","    x_img = resize(x_img, (360, 480, 1), mode = 'constant', preserve_range = True)\n","    # Load masks\n","    mask_id_ = id_.split('.')[0] + '_bin_mask.png'\n","    mask = img_to_array(load_img(\"/content/gdrive/My Drive/avc-dataset/MonuSeg/Training/GroundTruth/\"+mask_id_, grayscale=True))\n","    mask = resize(mask, (360, 480, 1), mode = 'constant', preserve_range = True)\n","    # Save images\n","    X[n] = x_img/255.0\n","    y[n] = mask/255.0"],"execution_count":22,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  \"\"\"Entry point for launching an IPython kernel.\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6563a5b2ca844182b758af2f476bdede","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py:104: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n","  warnings.warn('grayscale is deprecated. Please use '\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_pp4dc1shabb","colab_type":"code","colab":{}},"source":["# Split train and valid\n","X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=42)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T6eZXXZny_Ow","colab_type":"code","colab":{}},"source":["# Define Some metrics\n","## Dice Score\n","def dice_coef(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())\n","## F1 Score\n","def f1(y_true, y_pred):\n","    def recall(y_true, y_pred):\n","        \"\"\"Recall metric.\n","\n","        Only computes a batch-wise average of recall.\n","\n","        Computes the recall, a metric for multi-label classification of\n","        how many relevant items are selected.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","        recall = true_positives / (possible_positives + K.epsilon())\n","        return recall\n","\n","    def precision(y_true, y_pred):\n","        \"\"\"Precision metric.\n","\n","        Only computes a batch-wise average of precision.\n","\n","        Computes the precision, a metric for multi-label classification of\n","        how many selected items are relevant.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","    precision = precision(y_true, y_pred)\n","    recall = recall(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wsrwnEc534t2","colab_type":"code","colab":{}},"source":["import keras\n","from keras.layers import Layer, ZeroPadding2D, Cropping2D\n","import tensorflow as tf\n","from tensorflow.keras import backend as K\n","\n","class MaxPoolingWithIndices(keras.layers.Layer):\n","    def __init__(self, pool_size,strides,padding='SAME',**kwargs):\n","        super(MaxPoolingWithIndices, self).__init__(**kwargs)\n","        self.pool_size=pool_size\n","        self.strides=strides\n","        self.padding=padding\n","        return\n","    def call(self,x):\n","        pool_size=self.pool_size\n","        strides=self.strides\n","        if isinstance(pool_size,int):\n","            ps=[1,pool_size,pool_size,1]\n","        else:\n","            ps=[1,pool_size[0],pool_size[1],1]\n","        if isinstance(strides,int):\n","            st=[1,strides,strides,1]\n","        else:\n","            st=[1,strides[0],strides[1],1]\n","        output1,output2=tf.nn.max_pool_with_argmax(x,ps,st,self.padding)\n","        return [output1,output2]\n","    def compute_output_shape(self, input_shape):\n","        if isinstance(self.pool_size,int):\n","            output_shape=(input_shape[0],input_shape[1]//self.pool_size,input_shape[2]//self.pool_size,input_shape[3])\n","        else:\n","            output_shape=(input_shape[0],input_shape[1]//self.pool_size[0],input_shape[2]//self.pool_size[1],input_shape[3])\n","        return [output_shape,output_shape]\n","\n","\n","class UpSamplingWithIndices(Layer):\n","    def __init__(self, **kwargs):\n","        super(UpSamplingWithIndices, self).__init__(**kwargs)\n","        return\n","    def call(self,x):\n","        argmax=K.cast(K.flatten(x[1]),'int32')\n","        max_value=K.flatten(x[0])\n","        with tf.variable_scope(self.name):\n","            input_shape=K.shape(x[0])\n","            batch_size=input_shape[0]\n","            image_size=input_shape[1]*input_shape[2]*input_shape[3]\n","            output_shape=[input_shape[0],input_shape[1]*2,input_shape[2]*2,input_shape[3]]\n","            indices_0=K.flatten(tf.matmul(K.reshape(tf.range(batch_size),(batch_size,1)),K.ones((1,image_size),dtype='int32')))\n","            indices_1=argmax%(image_size*4)//(output_shape[2]*output_shape[3])\n","            indices_2=argmax%(output_shape[2]*output_shape[3])//output_shape[3]\n","            indices_3=argmax%output_shape[3]\n","            indices=tf.stack([indices_0,indices_1,indices_2,indices_3])\n","            output=tf.scatter_nd(K.transpose(indices),max_value,output_shape)\n","            return output\n","    def compute_output_shape(self, input_shape):\n","        return input_shape[0][0],input_shape[0][1]*2,input_shape[0][2]*2,input_shape[0][3]\n","\n","def CompositeConv(inputs,num_layers,num_features):\n","    output=inputs\n","    if isinstance(num_features,int):\n","        for i in range(num_layers):\n","            output=Conv2D(num_features,(7,7),padding='same')(output)\n","            output=BatchNormalization(axis=3)(output)\n","            output=Activation('relu')(output)\n","        return output\n","    for i in range(num_layers):\n","        output=Conv2D(num_features[i],(7,7),padding='same')(output)\n","        output=BatchNormalization(axis=3)(output)\n","        output=Activation('relu')(output)\n","    return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1GHFrvXM1KbX","colab_type":"code","colab":{}},"source":["inputs=Input(shape=(360,480,1))\n","\n","x = ZeroPadding2D(((12,12),(16,16)))(inputs)\n","\n","x=CompositeConv(x,2,64)\n","x,argmax1=MaxPoolingWithIndices(pool_size=2,strides=2)(x)\n","\n","x=CompositeConv(x,2,64)\n","x,argmax2=MaxPoolingWithIndices(pool_size=2,strides=2)(x)\n","\n","x=CompositeConv(x,3,64)\n","x,argmax3=MaxPoolingWithIndices(pool_size=2,strides=2)(x)\n","\n","x=CompositeConv(x,3,64)\n","x,argmax4=MaxPoolingWithIndices(pool_size=2,strides=2)(x)\n","\n","x=CompositeConv(x,3,64)\n","x,argmax5=MaxPoolingWithIndices(pool_size=2,strides=2)(x)\n","\n","x=UpSamplingWithIndices()([x,argmax5])\n","x=CompositeConv(x,3,64)\n","\n","x=UpSamplingWithIndices()([x,argmax4])\n","x=CompositeConv(x,3,64)\n","\n","x=UpSamplingWithIndices()([x,argmax3])\n","x=CompositeConv(x,3,64)\n","\n","x=UpSamplingWithIndices()([x,argmax2])\n","x=CompositeConv(x,2,64)\n","\n","x=UpSamplingWithIndices()([x,argmax1])\n","x=CompositeConv(x,2,[64,1])\n","\n","x=Activation('sigmoid')(x)\n","\n","y=Cropping2D(((12,12),(16,16)))(x)\n","\n","\n","model=Model(inputs=inputs,outputs=y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S0m3_P-L4XSD","colab_type":"code","outputId":"22d507f7-1eca-481c-9f94-367c0c07df23","executionInfo":{"status":"ok","timestamp":1585051079472,"user_tz":-300,"elapsed":225973,"user":{"displayName":"Abdul Shahid","photoUrl":"","userId":"02009174769082606407"}},"colab":{"base_uri":"https://localhost:8080/","height":313}},"source":["model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\", dice_coef, f1])\n","results=model.fit(X_train, y_train, batch_size=1, epochs=8,\n","                    validation_data=(X_valid, y_valid))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Train on 27 samples, validate on 3 samples\n","Epoch 1/8\n","27/27 [==============================] - 35s 1s/step - loss: 0.6987 - acc: 0.5156 - dice_coef: 0.3616 - f1: 0.4114 - val_loss: 3.8594 - val_acc: 0.2256 - val_dice_coef: 0.4542 - val_f1: 0.4649\n","Epoch 2/8\n","27/27 [==============================] - 25s 930ms/step - loss: 0.6658 - acc: 0.5827 - dice_coef: 0.4013 - f1: 0.5829 - val_loss: 0.7657 - val_acc: 0.3282 - val_dice_coef: 0.4319 - val_f1: 0.4826\n","Epoch 3/8\n","27/27 [==============================] - 25s 927ms/step - loss: 0.6582 - acc: 0.5903 - dice_coef: 0.4137 - f1: 0.6191 - val_loss: 0.7215 - val_acc: 0.3075 - val_dice_coef: 0.4322 - val_f1: 0.4779\n","Epoch 4/8\n","27/27 [==============================] - 25s 928ms/step - loss: 0.6554 - acc: 0.5925 - dice_coef: 0.4150 - f1: 0.6249 - val_loss: 0.7235 - val_acc: 0.3468 - val_dice_coef: 0.4329 - val_f1: 0.4959\n","Epoch 5/8\n","27/27 [==============================] - 25s 929ms/step - loss: 0.6546 - acc: 0.5914 - dice_coef: 0.4171 - f1: 0.6234 - val_loss: 0.6844 - val_acc: 0.4172 - val_dice_coef: 0.4085 - val_f1: 0.5082\n","Epoch 6/8\n","27/27 [==============================] - 25s 933ms/step - loss: 0.6517 - acc: 0.5975 - dice_coef: 0.4156 - f1: 0.6350 - val_loss: 0.7067 - val_acc: 0.3428 - val_dice_coef: 0.4304 - val_f1: 0.5003\n","Epoch 7/8\n","27/27 [==============================] - 25s 934ms/step - loss: 0.6506 - acc: 0.5960 - dice_coef: 0.4232 - f1: 0.6487 - val_loss: 0.7432 - val_acc: 0.2600 - val_dice_coef: 0.4420 - val_f1: 0.4653\n","Epoch 8/8\n","27/27 [==============================] - 25s 931ms/step - loss: 0.6507 - acc: 0.5962 - dice_coef: 0.4194 - f1: 0.6389 - val_loss: 0.6791 - val_acc: 0.4352 - val_dice_coef: 0.4118 - val_f1: 0.5309\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yPj-PJUVhac7","colab_type":"code","outputId":"754b628a-85bc-489d-8368-52acaae2de6e","executionInfo":{"status":"ok","timestamp":1585051080499,"user_tz":-300,"elapsed":226986,"user":{"displayName":"Abdul Shahid","photoUrl":"","userId":"02009174769082606407"}},"colab":{"base_uri":"https://localhost:8080/","height":98}},"source":["# Evaluate on validation set (this must be equals to the best log_loss)\n","loss, accuracy, f1_score, dice_score = model.evaluate(X_valid, y_valid, verbose=1)\n","\n","print(\"Loss:\", loss)\n","print(\"Accuracy:\", accuracy)\n","print(\"F1_score:\", f1_score)\n","print(\"Dice_score:\", dice_score)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["\r3/3 [==============================] - 1s 339ms/step\n","Loss: 0.6790745854377747\n","Accuracy: 0.4351601004600525\n","F1_score: 0.4169818162918091\n","Dice_score: 0.5396543145179749\n"],"name":"stdout"}]}]}